"""
Advanced RAG v3 - æ™ºèƒ½è‡ªé€‚åº” + å¯é æ€§å¢å¼º
æ ¸å¿ƒç‰¹æ€§:
1. QueryClassifier - æ™ºèƒ½æŸ¥è¯¢åˆ†ç±»
2. AdaptiveRetriever - è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥
3. AnswerValidator - ç­”æ¡ˆéªŒè¯ä¸å¼•ç”¨
"""
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../../..'))

from backend.app.services.embedding_service import EmbeddingService
from backend.app.services.vllm_service import get_vllm_service
import chromadb
from typing import List, Dict, Tuple
import numpy as np
from rank_bm25 import BM25Okapi
import jieba
import re


class QueryClassifier:
    """æŸ¥è¯¢åˆ†ç±»å™¨ - è¯†åˆ«æŸ¥è¯¢æ„å›¾"""
    
    def __init__(self, llm_service):
        self.llm_service = llm_service
    
    def classify(self, query: str) -> Dict:
        """
        åˆ†ç±»æŸ¥è¯¢ç±»å‹
        
        è¿”å›:
            {
                'type': 'factual' | 'example' | 'comparison' | 'context',
                'confidence': 0.0-1.0
            }
        """
        # å…ˆç”¨è§„åˆ™å¿«é€Ÿåˆ¤æ–­
        rule_based = self._rule_based_classify(query)
        if rule_based['confidence'] > 0.9:
            return rule_based
        
        # è§„åˆ™ä¸ç¡®å®šæ—¶ï¼Œä½¿ç”¨ LLM åˆ†ç±»
        return self._llm_based_classify(query)
    
    def _rule_based_classify(self, query: str) -> Dict:
        """åŸºäºè§„åˆ™çš„å¿«é€Ÿåˆ†ç±»"""
        query_lower = query.lower()
        
        # äº‹å®æŸ¥è¯¢ (factual): ç›´æ¥è¯¢é—®å‘éŸ³ã€è¯æ±‡
        factual_patterns = [
            r'æ€ä¹ˆè¯´', r'æ€ä¹ˆè¯»', r'æ€ä¹ˆå¿µ', r'å‘éŸ³', r'è¯»éŸ³',
            r'æ˜¯ä»€ä¹ˆ', r'å«ä»€ä¹ˆ', r'æ€ä¹ˆå†™'
        ]
        for pattern in factual_patterns:
            if re.search(pattern, query):
                return {'type': 'factual', 'confidence': 0.95}
        
        # ä¾‹å¥æŸ¥è¯¢ (example): è¯¢é—®ç”¨æ³•ã€ä¾‹å¥
        example_patterns = [
            r'æ€ä¹ˆç”¨', r'ç”¨æ³•', r'ä¾‹å¥', r'ä¸¾ä¾‹', r'é€ å¥',
            r'æ€ä¹ˆè¡¨è¾¾', r'å¦‚ä½•è¯´', r'æ€æ ·è¯´'
        ]
        for pattern in example_patterns:
            if re.search(pattern, query):
                return {'type': 'example', 'confidence': 0.95}
        
        # å¯¹æ¯”æŸ¥è¯¢ (comparison): è¯¢é—®åŒºåˆ«ã€å¯¹æ¯”
        comparison_patterns = [
            r'åŒºåˆ«', r'ä¸åŒ', r'å·®å¼‚', r'å¯¹æ¯”', r'ç›¸åŒ',
            r'å’Œ.*çš„å…³ç³»', r'è·Ÿ.*æ¯”'
        ]
        for pattern in comparison_patterns:
            if re.search(pattern, query):
                return {'type': 'comparison', 'confidence': 0.95}
        
        # èƒŒæ™¯æŸ¥è¯¢ (context): è¯¢é—®åŸå› ã€å†å²ã€èƒŒæ™¯
        context_patterns = [
            r'ä¸ºä»€ä¹ˆ', r'æ€ä¹ˆæ¥çš„', r'èµ·æº', r'å†å²', r'èƒŒæ™¯',
            r'ç”±æ¥', r'å…¸æ•…'
        ]
        for pattern in context_patterns:
            if re.search(pattern, query):
                return {'type': 'context', 'confidence': 0.95}
        
        # é»˜è®¤ä¸ºäº‹å®æŸ¥è¯¢
        return {'type': 'factual', 'confidence': 0.5}
    
    def _llm_based_classify(self, query: str) -> Dict:
        """åŸºäº LLM çš„ç²¾ç¡®åˆ†ç±»"""
        prompt = f"""è¯·åˆ¤æ–­ä»¥ä¸‹é—®é¢˜å±äºå“ªç§ç±»å‹ï¼Œåªè¿”å›ç±»å‹åç§°ï¼š

ç±»å‹è¯´æ˜ï¼š
- factual: è¯¢é—®äº‹å®ï¼Œå¦‚å‘éŸ³ã€è¯æ±‡ã€å®šä¹‰
- example: è¯¢é—®ç”¨æ³•ã€ä¾‹å¥ã€è¡¨è¾¾æ–¹å¼
- comparison: è¯¢é—®åŒºåˆ«ã€å¯¹æ¯”ã€å·®å¼‚
- context: è¯¢é—®èƒŒæ™¯ã€åŸå› ã€å†å²

é—®é¢˜ï¼š{query}

ç±»å‹ï¼ˆåªè¿”å› factual/example/comparison/context ä¸­çš„ä¸€ä¸ªï¼‰ï¼š"""

        try:
            response = self.llm_service.generate(
                prompt=prompt,
                max_tokens=10,
                temperature=0.1
            ).strip().lower()
            
            # æå–ç±»å‹
            if 'factual' in response:
                return {'type': 'factual', 'confidence': 0.85}
            elif 'example' in response:
                return {'type': 'example', 'confidence': 0.85}
            elif 'comparison' in response:
                return {'type': 'comparison', 'confidence': 0.85}
            elif 'context' in response:
                return {'type': 'context', 'confidence': 0.85}
        except:
            pass
        
        # LLM å¤±è´¥ï¼Œè¿”å›é»˜è®¤
        return {'type': 'factual', 'confidence': 0.5}


class AdaptiveRetriever:
    """è‡ªé€‚åº”æ£€ç´¢å™¨ - æ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´ç­–ç•¥"""
    
    # ä¸åŒæŸ¥è¯¢ç±»å‹çš„æ£€ç´¢ç­–ç•¥
    STRATEGIES = {
        'factual': {
            'retrieval_top_k': 10,
            'rerank_top_k': 2,
            'use_query_rewrite': False,
            'temperature': 0.3,
            'description': 'é«˜ç²¾åº¦æ£€ç´¢ï¼Œç›´æ¥ç»™å‡ºå‡†ç¡®ç­”æ¡ˆ'
        },
        'example': {
            'retrieval_top_k': 20,
            'rerank_top_k': 5,
            'use_query_rewrite': True,
            'temperature': 0.7,
            'description': 'é«˜å¬å›æ£€ç´¢ï¼Œæä¾›ä¸°å¯Œä¾‹å¥'
        },
        'comparison': {
            'retrieval_top_k': 15,
            'rerank_top_k': 4,
            'use_query_rewrite': True,
            'temperature': 0.5,
            'description': 'å¤šè§’åº¦æ£€ç´¢ï¼Œå…¨é¢å¯¹æ¯”åˆ†æ'
        },
        'context': {
            'retrieval_top_k': 12,
            'rerank_top_k': 3,
            'use_query_rewrite': True,
            'temperature': 0.6,
            'description': 'èƒŒæ™¯æ£€ç´¢ï¼Œè¡¥å……æ–‡åŒ–å†å²'
        }
    }
    
    @classmethod
    def get_strategy(cls, query_type: str) -> Dict:
        """è·å–æ£€ç´¢ç­–ç•¥"""
        return cls.STRATEGIES.get(query_type, cls.STRATEGIES['factual'])


class AnswerValidator:
    """ç­”æ¡ˆéªŒè¯å™¨ - è¯„ä¼°å¯é æ€§å¹¶æ·»åŠ å¼•ç”¨"""
    
    def __init__(self, llm_service):
        self.llm_service = llm_service
    
    def validate(self, query: str, answer: str, retrieved_docs: List[Dict]) -> Dict:
        """
        éªŒè¯ç­”æ¡ˆå¹¶æ·»åŠ å¼•ç”¨
        
        è¿”å›:
            {
                'answer': str,  # å¸¦å¼•ç”¨çš„ç­”æ¡ˆ
                'confidence': float,  # ç½®ä¿¡åº¦ 0-1
                'citations': List[str],  # å¼•ç”¨æ¥æº
                'warning': str  # è­¦å‘Šä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            }
        """
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰æ£€ç´¢æ–‡æ¡£
        if not retrieved_docs or len(retrieved_docs) == 0:
            return {
                'answer': "æŠ±æ­‰ï¼Œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚å»ºè®®æ‚¨æŸ¥é˜…ä¸“ä¸šçš„è†ç”°è¯è¯å…¸æˆ–å’¨è¯¢å½“åœ°è¯­è¨€ä¸“å®¶ã€‚",
                'confidence': 0.0,
                'citations': [],
                'warning': 'æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£'
            }
        
        # 2. ä¸€è‡´æ€§æ£€æŸ¥
        consistency_score = self._check_consistency(answer, retrieved_docs)
        
        # 3. æ·»åŠ å¼•ç”¨
        answer_with_citations, citations = self._add_citations(answer, retrieved_docs)
        
        # 4. ç”Ÿæˆè­¦å‘Š
        warning = None
        if consistency_score < 0.5:
            warning = 'æ­¤ç­”æ¡ˆç½®ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®ä»”ç»†æ ¸å¯¹'
            answer_with_citations = f"âš ï¸ æ³¨æ„ï¼š{warning}\n\n{answer_with_citations}"
        elif consistency_score < 0.7:
            warning = 'æ­¤ç­”æ¡ˆå¯èƒ½ä¸å®Œå…¨å‡†ç¡®'
        
        return {
            'answer': answer_with_citations,
            'confidence': consistency_score,
            'citations': citations,
            'warning': warning
        }
    
    def _check_consistency(self, answer: str, docs: List[Dict]) -> float:
        """
        æ£€æŸ¥ç­”æ¡ˆä¸æ£€ç´¢æ–‡æ¡£çš„ä¸€è‡´æ€§
        
        ç®€åŒ–ç‰ˆæœ¬ï¼šåŸºäºå…³é”®è¯é‡å åº¦
        """
        # æå–ç­”æ¡ˆä¸­çš„å…³é”®è¯
        answer_tokens = set(jieba.cut(answer))
        
        # è®¡ç®—ä¸æ¯ä¸ªæ–‡æ¡£çš„é‡å åº¦
        overlaps = []
        for doc in docs:
            doc_tokens = set(jieba.cut(doc['content']))
            if len(doc_tokens) > 0:
                overlap = len(answer_tokens & doc_tokens) / len(doc_tokens)
                overlaps.append(overlap)
        
        # è¿”å›å¹³å‡é‡å åº¦
        if overlaps:
            return min(sum(overlaps) / len(overlaps) * 2, 1.0)  # æ”¾å¤§åé™åˆ¶åœ¨1.0
        return 0.5  # é»˜è®¤ä¸­ç­‰ç½®ä¿¡åº¦
    
    def _add_citations(self, answer: str, docs: List[Dict]) -> Tuple[str, List[str]]:
        """
        ä¸ºç­”æ¡ˆæ·»åŠ å¼•ç”¨æ ‡æ³¨
        
        ç®€åŒ–ç‰ˆæœ¬ï¼šåœ¨ç­”æ¡ˆæœ«å°¾æ·»åŠ å‚è€ƒæ–‡æ¡£
        """
        citations = []
        for i, doc in enumerate(docs[:3], 1):  # æœ€å¤šå¼•ç”¨3ä¸ªæ–‡æ¡£
            # æå–æ–‡æ¡£å…³é”®ä¿¡æ¯
            content = doc['content']
            citation = f"[{i}] {content[:80]}..."
            citations.append(citation)
        
        # æ„å»ºå¸¦å¼•ç”¨çš„ç­”æ¡ˆ
        if citations:
            citation_text = "\n\nğŸ“š å‚è€ƒæ¥æºï¼š\n" + "\n".join(citations)
            return answer + citation_text, citations
        
        return answer, []


class AdvancedRAGv3:
    """Advanced RAG v3 - æ™ºèƒ½è‡ªé€‚åº” + å¯é æ€§å¢å¼º"""
    
    def __init__(
        self,
        collection_name: str = "putian_dialect",
        embedding_model_path: str = "/home/zl/LLM/bge-small-zh-v1.5",
        reranker_model_path: str = "BAAI/bge-reranker-base",
        chroma_db_path: str = "/home/zl/LLM/chroma_db_putian",
        vllm_api_url: str = "http://127.0.0.1:8001/v1"
    ):
        """åˆå§‹åŒ–"""
        print("=" * 60)
        print("åˆå§‹åŒ– Advanced RAG v3 ç³»ç»Ÿ")
        print("ç‰¹æ€§: æ™ºèƒ½è‡ªé€‚åº” + å¯é æ€§å¢å¼º")
        print("=" * 60)
        
        # 1. Embedding
        print("\n[1/7] åŠ è½½ Embedding æ¨¡å‹...")
        self.embedding_service = EmbeddingService(model_path=embedding_model_path)
        print(f"âœ“ Embedding: {embedding_model_path}")
        
        # 2. ChromaDB
        print("\n[2/7] è¿æ¥å‘é‡æ•°æ®åº“...")
        self.chroma_client = chromadb.PersistentClient(path=chroma_db_path)
        self.collection = self.chroma_client.get_collection(name=collection_name)
        doc_count = self.collection.count()
        print(f"âœ“ æ•°æ®åº“: {collection_name} ({doc_count} æ–‡æ¡£)")
        
        # 3. BM25
        print("\n[3/7] æ„å»º BM25 ç´¢å¼•...")
        all_docs = self.collection.get(include=["documents"])
        self.all_documents = all_docs['documents']
        self.tokenized_docs = [list(jieba.cut(doc)) for doc in self.all_documents]
        self.bm25 = BM25Okapi(self.tokenized_docs)
        print(f"âœ“ BM25 ç´¢å¼•: {len(self.all_documents)} æ–‡æ¡£")
        
        # 4. Reranker
        print("\n[4/7] åŠ è½½ Reranker...")
        from FlagEmbedding import FlagReranker
        local_path = "/home/zl/LLM/bge-reranker-base"
        model_path = local_path if os.path.exists(local_path) else reranker_model_path
        try:
            self.reranker = FlagReranker(model_path, use_fp16=True, device="cuda:1", num_workers=0)
            print("âœ“ Reranker åŠ è½½å®Œæˆ")
        except:
            print("âš  Reranker ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€åŒ–æ–¹æ¡ˆ")
            self.reranker = None
        
        # 5. vLLM
        print("\n[5/7] è¿æ¥ vLLM æœåŠ¡...")
        self.llm_service = get_vllm_service(vllm_api_url)
        
        # 6. v3 æ–°ç»„ä»¶ï¼šæ™ºèƒ½æ¨¡å—
        print("\n[6/7] åˆå§‹åŒ–æ™ºèƒ½ç»„ä»¶...")
        self.query_classifier = QueryClassifier(self.llm_service)
        self.adaptive_retriever = AdaptiveRetriever()
        self.answer_validator = AnswerValidator(self.llm_service)
        print("âœ“ Query Classifier, Adaptive Retriever, Answer Validator")
        
        # 7. æç¤ºè¯æ¨¡æ¿
        print("\n[7/7] åŠ è½½æç¤ºè¯æ¨¡æ¿...")
        self.prompt_templates = self._init_prompt_templates()
        print("âœ“ 4 ç§æŸ¥è¯¢ç±»å‹çš„ä¸“ç”¨æ¨¡æ¿")
        
        print("\n" + "=" * 60)
        print("âœ“ Advanced RAG v3 åˆå§‹åŒ–å®Œæˆï¼")
        print("=" * 60)
    
    def _init_prompt_templates(self) -> Dict:
        """åˆå§‹åŒ–ä¸åŒç±»å‹çš„æç¤ºè¯æ¨¡æ¿"""
        return {
            'factual': """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è†ç”°è¯ï¼ˆè†ä»™æ–¹è¨€ï¼‰ä¸“å®¶åŠ©æ‰‹ã€‚

# ä»»åŠ¡
å‡†ç¡®å›ç­”ç”¨æˆ·å…³äºè†ç”°è¯å‘éŸ³ã€è¯æ±‡çš„é—®é¢˜ã€‚

# å›ç­”è¦æ±‚
1. ç›´æ¥ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆ
2. æä¾›å›½é™…éŸ³æ ‡æ ‡æ³¨
3. ç®€æ´æ˜äº†ï¼Œä¸è¶…è¿‡100å­—

# å‚è€ƒèµ„æ–™
{context}

# ç”¨æˆ·é—®é¢˜
{query}

# ä½ çš„å›ç­”
""",
            'example': """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è†ç”°è¯ï¼ˆè†ä»™æ–¹è¨€ï¼‰ä¸“å®¶åŠ©æ‰‹ã€‚

# ä»»åŠ¡
æä¾›è†ç”°è¯è¯æ±‡çš„å®ç”¨ä¾‹å¥å’Œç”¨æ³•è¯´æ˜ã€‚

# å›ç­”è¦æ±‚
1. ç»™å‡ºè¯æ±‡çš„åŸºæœ¬å«ä¹‰
2. æä¾›3-5ä¸ªå®ç”¨ä¾‹å¥
3. æ¯ä¸ªä¾‹å¥åŒ…å«è†ç”°è¯å’Œæ™®é€šè¯å¯¹ç…§

# å‚è€ƒèµ„æ–™
{context}

# ç”¨æˆ·é—®é¢˜
{query}

# ä½ çš„å›ç­”
""",
            'comparison': """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è†ç”°è¯ï¼ˆè†ä»™æ–¹è¨€ï¼‰ä¸“å®¶åŠ©æ‰‹ã€‚

# ä»»åŠ¡
å¯¹æ¯”åˆ†æè†ç”°è¯è¯æ±‡çš„åŒºåˆ«ã€å¼‚åŒæˆ–å…³ç³»ã€‚

# å›ç­”è¦æ±‚
1. æ¸…æ™°è¯´æ˜å¯¹æ¯”çš„å‡ ä¸ªæ–¹é¢
2. æŒ‡å‡ºä¸»è¦åŒºåˆ«å’Œå…±åŒç‚¹
3. æä¾›ä¾‹å¥è¯´æ˜
4. ç»“æ„åŒ–è¾“å‡ºï¼Œä½¿ç”¨åˆ—è¡¨æˆ–è¡¨æ ¼

# å‚è€ƒèµ„æ–™
{context}

# ç”¨æˆ·é—®é¢˜
{query}

# ä½ çš„å›ç­”
""",
            'context': """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è†ç”°è¯ï¼ˆè†ä»™æ–¹è¨€ï¼‰ä¸“å®¶åŠ©æ‰‹ã€‚

# ä»»åŠ¡
è§£é‡Šè†ç”°è¯è¯æ±‡çš„èƒŒæ™¯ã€ç”±æ¥æˆ–æ–‡åŒ–å†å²ã€‚

# å›ç­”è¦æ±‚
1. è¯´æ˜è¯æ±‡çš„èµ·æºæˆ–ç”±æ¥
2. è¡¥å……æ–‡åŒ–æˆ–å†å²èƒŒæ™¯
3. è¯´æ˜ä¸å¤æ±‰è¯­æˆ–å…¶ä»–æ–¹è¨€çš„å…³ç³»
4. å†…å®¹ä¸°å¯Œï¼Œ200å­—å·¦å³

# å‚è€ƒèµ„æ–™
{context}

# ç”¨æˆ·é—®é¢˜
{query}

# ä½ çš„å›ç­”
"""
        }
    
    def vector_search(self, query: str, top_k: int = 20) -> List[Dict]:
        """å‘é‡æ£€ç´¢"""
        query_emb = self.embedding_service.encode(query)
        query_emb_list = query_emb.tolist()
        
        results = self.collection.query(
            query_embeddings=query_emb_list,
            n_results=top_k,
            include=["documents", "distances"]
        )
        
        retrieved = []
        if results['documents'] and len(results['documents'][0]) > 0:
            for i, doc in enumerate(results['documents'][0]):
                distance = results['distances'][0][i]
                retrieved.append({
                    'content': doc,
                    'score': 1 - distance,
                    'rank': i + 1
                })
        
        return retrieved
    
    def bm25_search(self, query: str, top_k: int = 20) -> List[Dict]:
        """BM25 æ£€ç´¢"""
        tokenized_query = list(jieba.cut(query))
        scores = self.bm25.get_scores(tokenized_query)
        
        top_indices = np.argsort(scores)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            if scores[idx] > 0:
                results.append({
                    'content': self.all_documents[idx],
                    'score': float(scores[idx]),
                    'rank': len(results) + 1
                })
        
        return results
    
    def hybrid_search(self, query: str, top_k: int = 20) -> List[Dict]:
        """æ··åˆæ£€ç´¢ + RRF"""
        # Vector + BM25
        vector_results = self.vector_search(query, top_k=top_k)
        bm25_results = self.bm25_search(query, top_k=top_k)
        
        # RRF èåˆ
        all_docs = {}
        k = 60
        
        for result in vector_results:
            doc = result['content']
            if doc not in all_docs:
                all_docs[doc] = 0
            all_docs[doc] += 1.0 / (k + result['rank'])
        
        for result in bm25_results:
            doc = result['content']
            if doc not in all_docs:
                all_docs[doc] = 0
            all_docs[doc] += 1.0 / (k + result['rank'])
        
        # æ’åº
        ranked = sorted(all_docs.items(), key=lambda x: x[1], reverse=True)
        
        return [{
            'content': doc,
            'score': score,
            'rank': i + 1
        } for i, (doc, score) in enumerate(ranked[:top_k])]
    
    def rerank(self, query: str, documents: List[str], top_k: int = 5) -> List[Dict]:
        """é‡æ’åº"""
        if not documents:
            return []
        
        if self.reranker is None:
            return [{
                'content': doc,
                'score': 1.0 - (i * 0.1),
                'rank': i + 1
            } for i, doc in enumerate(documents[:top_k])]
        
        pairs = [[query, doc] for doc in documents]
        scores = self.reranker.compute_score(pairs)
        
        if not isinstance(scores, list):
            scores = [scores]
        
        # å®‰å…¨çš„ float è½¬æ¢
        def safe_float(score):
            if hasattr(score, 'flatten'):
                flat = score.flatten()
                return float(flat[0]) if len(flat) > 0 else 0.0
            elif hasattr(score, 'item'):
                try:
                    return float(score.item())
                except (ValueError, TypeError):
                    return float(score[0]) if hasattr(score, '__getitem__') else 0.0
            elif hasattr(score, '__float__'):
                return float(score)
            elif isinstance(score, (list, tuple)) and len(score) > 0:
                return float(score[0])
            else:
                return float(score)
        
        doc_score_pairs = list(zip(documents, scores))
        doc_score_pairs.sort(key=lambda x: safe_float(x[1]), reverse=True)
        
        return [{
            'content': doc,
            'score': safe_float(score),
            'rank': i + 1
        } for i, (doc, score) in enumerate(doc_score_pairs[:top_k])]
    
    def generate(
        self,
        query: str,
        verbose: bool = True
    ) -> Dict:
        """æ‰§è¡Œå®Œæ•´çš„ Advanced RAG v3 æµç¨‹"""
        if verbose:
            print("\n" + "=" * 60)
            print(f"æŸ¥è¯¢: {query}")
            print("=" * 60)
        
        # 1. æŸ¥è¯¢åˆ†ç±»
        if verbose:
            print("\n[æ­¥éª¤ 1] æ™ºèƒ½æŸ¥è¯¢åˆ†ç±»...")
        
        classification = self.query_classifier.classify(query)
        query_type = classification['type']
        confidence = classification['confidence']
        
        if verbose:
            print(f"âœ“ æŸ¥è¯¢ç±»å‹: {query_type} (ç½®ä¿¡åº¦: {confidence:.2f})")
            print(f"  è¯´æ˜: {self.adaptive_retriever.get_strategy(query_type)['description']}")
        
        # 2. è·å–è‡ªé€‚åº”ç­–ç•¥
        if verbose:
            print(f"\n[æ­¥éª¤ 2] è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥...")
        
        strategy = self.adaptive_retriever.get_strategy(query_type)
        
        if verbose:
            print(f"âœ“ ç­–ç•¥é…ç½®:")
            print(f"  - å¬å›æ–‡æ¡£æ•°: {strategy['retrieval_top_k']}")
            print(f"  - é‡æ’åºä¿ç•™: {strategy['rerank_top_k']}")
            print(f"  - æŸ¥è¯¢æ”¹å†™: {'å¼€å¯' if strategy['use_query_rewrite'] else 'å…³é—­'}")
            print(f"  - ç”Ÿæˆæ¸©åº¦: {strategy['temperature']}")
        
        # 3. æ··åˆæ£€ç´¢
        if verbose:
            print(f"\n[æ­¥éª¤ 3] æ··åˆæ£€ç´¢ (Vector + BM25)...")
        
        hybrid_results = self.hybrid_search(query, top_k=strategy['retrieval_top_k'])
        
        if verbose:
            print(f"âœ“ å¬å› {len(hybrid_results)} ä¸ªå€™é€‰æ–‡æ¡£")
        
        # 4. Reranker
        if verbose:
            print(f"\n[æ­¥éª¤ 4] Reranker é‡æ’åº...")
        
        docs_to_rerank = [r['content'] for r in hybrid_results]
        reranked = self.rerank(query, docs_to_rerank, top_k=strategy['rerank_top_k'])
        
        if verbose:
            print(f"âœ“ ä¿ç•™ Top-{len(reranked)} æ–‡æ¡£")
        
        # 5. æ„å»ºæç¤ºè¯
        if verbose:
            print(f"\n[æ­¥éª¤ 5] æ„å»ºä¸“ç”¨æç¤ºè¯ ({query_type})...")
        
        context = "\n\n".join([
            f"ã€æ–‡æ¡£ {doc['rank']}ã€‘\n{doc['content']}"
            for doc in reranked
        ])
        
        template = self.prompt_templates[query_type]
        prompt = template.format(context=context, query=query)
        
        if verbose:
            print(f"âœ“ ä½¿ç”¨ {query_type} ç±»å‹ä¸“ç”¨æ¨¡æ¿")
        
        # 6. vLLM ç”Ÿæˆ
        if verbose:
            print("\n[æ­¥éª¤ 6] vLLM ç”Ÿæˆç­”æ¡ˆ...")
        
        answer = self.llm_service.generate(
            prompt=prompt,
            max_tokens=512,
            temperature=strategy['temperature']
        )
        
        if verbose:
            print("âœ“ ç”Ÿæˆå®Œæˆ")
        
        # 7. ç­”æ¡ˆéªŒè¯
        if verbose:
            print("\n[æ­¥éª¤ 7] ç­”æ¡ˆéªŒè¯ä¸å¼•ç”¨...")
        
        validation = self.answer_validator.validate(query, answer, reranked)
        
        if verbose:
            print(f"âœ“ ç½®ä¿¡åº¦: {validation['confidence']:.2f}")
            print(f"âœ“ å¼•ç”¨æ•°: {len(validation['citations'])}")
            if validation['warning']:
                print(f"âš  è­¦å‘Š: {validation['warning']}")
        
        # 8. è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
        if verbose:
            print("\n" + "=" * 60)
            print("æœ€ç»ˆç­”æ¡ˆ:")
            print("=" * 60)
            print(validation['answer'])
            print("=" * 60)
        
        return {
            'query': query,
            'query_type': query_type,
            'classification_confidence': confidence,
            'strategy': strategy,
            'answer': validation['answer'],
            'raw_answer': answer,
            'confidence': validation['confidence'],
            'citations': validation['citations'],
            'warning': validation['warning'],
            'retrieved_docs': reranked,
            'num_docs': len(reranked)
        }


def main():
    """æµ‹è¯• Advanced RAG v3"""
    rag = AdvancedRAGv3()
    
    test_queries = [
        "è†ç”°è¯ä¸­'åƒ'æ€ä¹ˆè¯´ï¼Ÿ",  # factual
        "é£Ÿå­—æ€ä¹ˆç”¨ï¼Ÿ",  # example
        "é£Ÿå’Œåƒæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",  # comparison
        "ä¸ºä»€ä¹ˆè†ç”°è¯å«'é£Ÿ'è€Œä¸æ˜¯'åƒ'ï¼Ÿ",  # context
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n\n{'='*80}")
        print(f"æµ‹è¯• {i}/{len(test_queries)}")
        print(f"{'='*80}")
        
        result = rag.generate(query=query, verbose=True)
        
        if i < len(test_queries):
            input("\næŒ‰å›è½¦ç»§ç»­...")


if __name__ == "__main__":
    main()
