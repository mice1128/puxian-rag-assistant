"""
Naive RAG - åŸºç¡€æ£€ç´¢å¢å¼ºç”Ÿæˆ
ä½¿ç”¨ vLLM ä½œä¸ºæ¨ç†å¼•æ“
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '../../..'))

from backend.app.services.embedding_service import EmbeddingService
from backend.app.services.vllm_service import get_vllm_service
import chromadb


class NaiveRAG:
    """Naive RAG å®ç° - Vector æ£€ç´¢ + vLLM ç”Ÿæˆ"""
    
    def __init__(
        self,
        collection_name: str = "putian_dialect",
        embedding_model_path: str = "/home/zl/LLM/bge-small-zh-v1.5",
        chroma_db_path: str = "/home/zl/LLM/chroma_db_putian",
        vllm_api_url: str = "http://127.0.0.1:8001/v1"
    ):
        """
        åˆå§‹åŒ– Naive RAG
        
        Args:
            collection_name: ChromaDB é›†åˆåç§°
            embedding_model_path: Embedding æ¨¡å‹è·¯å¾„
            chroma_db_path: ChromaDB æ•°æ®åº“è·¯å¾„
            vllm_api_url: vLLM API æœåŠ¡åœ°å€
        """
        print("=" * 60)
        print("åˆå§‹åŒ– Naive RAG ç³»ç»Ÿ")
        print("=" * 60)
        
        # 1. åˆå§‹åŒ– Embedding æœåŠ¡
        print("\n[1/3] åŠ è½½ Embedding æ¨¡å‹...")
        self.embedding_service = EmbeddingService(
            model_path=embedding_model_path
        )
        print(f"âœ“ Embedding æ¨¡å‹åŠ è½½å®Œæˆ: {embedding_model_path}")
        
        # 2. è¿æ¥ ChromaDB
        print("\n[2/3] è¿æ¥ ChromaDB...")
        self.chroma_client = chromadb.PersistentClient(path=chroma_db_path)
        self.collection = self.chroma_client.get_collection(name=collection_name)
        print(f"âœ“ ChromaDB è¿æ¥æˆåŠŸ: {collection_name}")
        print(f"  æ•°æ®åº“è·¯å¾„: {chroma_db_path}")
        print(f"  æ–‡æ¡£æ€»æ•°: {self.collection.count()}")
        
        # 3. åˆå§‹åŒ– vLLM æœåŠ¡
        print("\n[3/3] è¿æ¥ vLLM æ¨ç†æœåŠ¡...")
        self.llm_service = get_vllm_service(vllm_api_url)
        
        print("\n" + "=" * 60)
        print("âœ“ Naive RAG åˆå§‹åŒ–å®Œæˆï¼")
        print("=" * 60)
    
    def retrieve(self, query: str, top_k: int = 5) -> list:
        """
        å‘é‡æ£€ç´¢
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            top_k: è¿”å›å‰ k ä¸ªç›¸å…³æ–‡æ¡£
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        # 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embedding_service.encode(query)
        # query_embedding å½¢çŠ¶æ˜¯ (1, 512)ï¼Œtolist() åæ˜¯ [[...]]
        query_emb_list = query_embedding.tolist()
        
        # 2. å‘é‡æ£€ç´¢
        results = self.collection.query(
            query_embeddings=query_emb_list,
            n_results=top_k
        )
        
        # 3. æ ¼å¼åŒ–ç»“æœ
        retrieved_docs = []
        if results and results['documents'] and len(results['documents']) > 0:
            for i, doc in enumerate(results['documents'][0]):
                metadata = results['metadatas'][0][i] if results['metadatas'] else {}
                distance = results['distances'][0][i] if results['distances'] else 0
                
                retrieved_docs.append({
                    'content': doc,
                    'metadata': metadata,
                    'score': 1 - distance,  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
                    'rank': i + 1
                })
        
        return retrieved_docs
    
    def build_prompt(self, query: str, context_docs: list) -> str:
        """
        æ„å»º RAG æç¤ºè¯
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            context_docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        
        Returns:
            å®Œæ•´çš„æç¤ºè¯
        """
        # æ‹¼æ¥ä¸Šä¸‹æ–‡
        context_text = "\n\n".join([
            f"[æ–‡æ¡£ {doc['rank']}]:\n{doc['content']}"
            for doc in context_docs
        ])
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªè†ç”°è¯ï¼ˆè†ä»™æ–¹è¨€ï¼‰ä¸“å®¶åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹å‚è€ƒèµ„æ–™å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

# å‚è€ƒèµ„æ–™ï¼š
{context_text}

# ç”¨æˆ·é—®é¢˜ï¼š
{query}

# è¦æ±‚ï¼š
1. åŸºäºå‚è€ƒèµ„æ–™å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. å¦‚æœå‚è€ƒèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®è¯´æ˜
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€æ˜“æ‡‚
4. å¦‚æœæ¶‰åŠè†ç”°è¯çš„å‘éŸ³æˆ–è¯æ±‡ï¼Œè¯·æä¾›è¯¦ç»†è§£é‡Š

è¯·å›ç­”ï¼š"""

        return prompt
    
    def generate(self, query: str, top_k: int = 5, verbose: bool = True) -> dict:
        """
        æ‰§è¡Œå®Œæ•´çš„ RAG æµç¨‹
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            top_k: æ£€ç´¢æ–‡æ¡£æ•°é‡
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        
        Returns:
            åŒ…å«ç­”æ¡ˆå’Œä¸­é—´ç»“æœçš„å­—å…¸
        """
        if verbose:
            print("\n" + "=" * 60)
            print(f"æŸ¥è¯¢: {query}")
            print("=" * 60)
        
        # 1. æ£€ç´¢
        if verbose:
            print("\n[æ­¥éª¤ 1] å‘é‡æ£€ç´¢...")
        retrieved_docs = self.retrieve(query, top_k)
        
        if verbose:
            print(f"âœ“ æ£€ç´¢åˆ° {len(retrieved_docs)} ä¸ªç›¸å…³æ–‡æ¡£:")
            for doc in retrieved_docs[:3]:  # åªæ˜¾ç¤ºå‰ 3 ä¸ª
                print(f"  - [æ’å {doc['rank']}] ç›¸ä¼¼åº¦: {doc['score']:.3f}")
                print(f"    å†…å®¹é¢„è§ˆ: {doc['content'][:100]}...")
        
        # 2. æ„å»ºæç¤ºè¯
        if verbose:
            print("\n[æ­¥éª¤ 2] æ„å»º RAG æç¤ºè¯...")
        prompt = self.build_prompt(query, retrieved_docs)
        
        if verbose:
            print(f"âœ“ æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
        
        # 3. ç”Ÿæˆç­”æ¡ˆ
        if verbose:
            print("\n[æ­¥éª¤ 3] è°ƒç”¨ vLLM ç”Ÿæˆç­”æ¡ˆ...")
        answer = self.llm_service.generate(
            prompt=prompt,
            max_tokens=512,
            temperature=0.7,
            top_p=0.9
        )
        
        if verbose:
            print("âœ“ ç”Ÿæˆå®Œæˆ")
            print("\n" + "=" * 60)
            print("æœ€ç»ˆç­”æ¡ˆ:")
            print("=" * 60)
            print(answer)
            print("=" * 60)
        
        return {
            'query': query,
            'answer': answer,
            'retrieved_docs': retrieved_docs,
            'prompt': prompt,
            'num_docs': len(retrieved_docs)
        }


def main():
    """æµ‹è¯• Naive RAG"""
    # åˆå§‹åŒ–
    rag = NaiveRAG()
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "è†ç”°è¯ä¸­'é£Ÿ'æ€ä¹ˆè¯´ï¼Ÿ",
        "ä»‹ç»ä¸€ä¸‹è†ç”°è¯çš„å£°è°ƒç³»ç»Ÿ",
        "è†ç”°è¯å’Œæ™®é€šè¯æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"
    ]
    
    print("\n\n" + "ğŸ”¥" * 30)
    print("å¼€å§‹æµ‹è¯• Naive RAG")
    print("ğŸ”¥" * 30)
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n\n{'='*80}")
        print(f"æµ‹è¯• {i}/{len(test_queries)}")
        print(f"{'='*80}")
        
        result = rag.generate(query, top_k=3, verbose=True)
        
        input("\næŒ‰å›è½¦é”®ç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...")


if __name__ == "__main__":
    main()
